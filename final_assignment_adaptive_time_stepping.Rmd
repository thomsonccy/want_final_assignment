---
title: "Final assignment: Adaptive Time Stepping"
author: "Thomson Chow, Isabella Anglin, Jiri Svatos, Xuwen Wang"
date: "01/02/2024"
output:
  html_document:
    css: want.css
    toc: yes
    toc_depth: 1
---


# Introduction
During the exercises on Finite Differences, you have experienced several times that the model can become instable or at least can start oscillating. Often, this could be resolved with decreasing the time step over which the calculation was performed. This is, however, a rather expensive solution, because a smaller time step means many more calculations while maybe, this smaller time step is not needed throughout the complete simulation period. Therefore, adaptive time stepping schemes exist; when needed, a smaller time step is taken, and when not needed, the time step is increased again.  

# The model 
We will implement an adaptive time stepping scheme for the most simple model we dealt with; the emptying reservoir without input. 

![](reservoir_properties.png)



*Single linear reservoir with outlet properties.*  

# First assignment
Implement an adaptive time stepping scheme. For this, you have to define criteria for when the time step has to decrease (and how much). This can be based on the difference between two schemes. However, you don't want to do the same calculation twice, because then you might as well half the step size directly. Therefore, use two schemes where one scheme is an intergral part of the other scheme. The simplest example is Euler Forward and Heun's Method. Heun's Method looks as follows:

$$\widetilde{s}= s(t) + \Delta t f(t,s(t))$$

Where $\tilde{s}$ is a sub-step equal to Euler Forward. Subsequently, $t+\Delta t$ is obtained as:
$$ s(t+\Delta t)= s(t) + \frac{\Delta t}{2}(f(t,s(t))+f(t+\Delta t,\widetilde{s}))$$


Another option is for instance the Cash-Karp method, where two Runge-Kutta schemes are compared. Implement the schemes, define an error tolerance, and adapt the time step when the error exceeds this tolerance. Compare your results to the analytical solution, to evaluate the trade-off between error and number of evaluations-. 

# Second assignment
Conduct a sensitivity analysis. 
- Decide for yourself whether you want to conduct a local or global sensitivity analysis.
- Decide on which parameters you want to conduct sensitivity analysis - the parameters from the reservoir, or the parameters of your adaptive time stepping scheme, or both and their interaction? 

# Further exploration
You are free to explore any other questions that arise with the model. For example:
- Use variable input, such as the Hupsel data from assignment 6, week 1. What are the water balance errors and do these decrease with a variable time stepping scheme? 
- What happens to the results if you add complexity to my model? (e.g. by introducing a second outlet)
- What is the relation between time steps and parameter sensitivity?

$$s(t + \Delta t)=s(t)+\dfrac{\Delta t}{A}
\left(Q_{in}-\alpha_{res.up}(s(t)-level_{res.up})-\alpha_{res.lw}\:s(t)\right)\\$$

# Setting the Working Directory
Ensure the working directory is set to the folder "want_final_assignment_group_12". The following code checks the current working directory:

```{R}
# Outputs the current working directory
getwd()
```

# Solution

## Loading Custom Functions
First, we load the necessary functions from the "reservoir_functions.R" script. This script contains custom functions for our simulation.
```{R}
source("reservoir_functions.R")
```


## Euler Forward and Heun's Method
We compare the absolute difference between the results from Euler Forward and Heun's Method. If this difference is smaller than a predefined absolute tolerance, the result from Heun's method is accepted. If the difference exceeds the tolerance, the calculation is repeated with a new time step. The new time step is adjusted as follows:
$$dt_{new}=dt_{old}\cdot factor$$
where $factor$ is a user-defined value. This process continues until the absolute difference falls below the tolerance level.


# Implementation
```{R}
# Discretisation Parameters
begin_time <- 0 # start time of the simulation
end_time <- 50 # end time of the simulation
dt_start <- 5 # delta t; time discretisation
initial_state <- 3 # water level of the reservoir at the beginning of the simulation
factor <- 0.8 # factor which delta t deceases each time the absolute difference of the two methods is larger than tolerance
tolerance <- 0.01 # user-defined max absolute difference of the two methods accepted

# Reservoir Parameters
A <- 4.0 # area
alpha <- 1.5 # decay constant


# Running the simulation
simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)


# Extract results
result_time <- simulation_results$time
result_state <- simulation_results$state


# Analytical Solution for Comparison
time_sequence <- seq(begin_time, end_time, by = 0.1)
analytic_state <- initial_state * exp(-time_sequence * alpha / A)
analytic_state_at_discrete_time_step <- initial_state * exp(-result_time * alpha / A)


# Plotting Results
plot(result_time, result_state, type = "o", xlab = "time", ylab = "state", col = "blue")
lines(result_time, analytic_state_at_discrete_time_step, col = "grey", lwd = 2)
title(main = "Emptying reservoir")
grid()

# Performance Metrics

# Number of function evaluations
num_eval <- length(result_time)
print(paste("Number of function evaluations:", num_eval))

# Absolute error at each time step
analytical_comparison <- abs(analytic_state_at_discrete_time_step - result_state)

# Root-mean-square deviation
RMSD <- sqrt(sum(analytical_comparison^2) / length(analytical_comparison))
print(paste("Root Mean Square Deviation (RMSD):", RMSD))
```


# Evaluate Gain between Fixed and Variable Time-Stepping
This section evaluates the performance of fixed and variable time-stepping methods in a reservoir simulation. We aim to understand the trade-off between accuracy (measured using RMSE) and computational efficiency (measured by the number of function evaluations).


#### Fixed Time Stepping (Heun's) 
```{R}
begin_time = 0 # [s]
end_time = 50 # [s]
dt_start   = 3 # [s]
initial_state = 3 # [m]
A = 4.0 # [m2]
alpha = 1.5 
factor = 0.8 # [-]
tolerance = 0.01 

# Run the FIXED simulation
simulation_results_fixed = simulate_reservoir_fixed(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance,calculate_heuns_reservoir)

# Extract results for plotting and further analysis
result_time_fixed = simulation_results_fixed$time
result_state_fixed = simulation_results_fixed$state

# state of analytical solution to compare with numerical solution at every time step
analytic_state_at_discrete_time_step_fixed=initial_state * exp(-result_time_fixed*alpha/A)

# Plot the results 
plot(result_time_fixed, result_state_fixed,type='o', xlab="Time [s]", ylab="Water level [m]", col="blue")
lines(result_time_fixed, analytic_state_at_discrete_time_step_fixed, col='grey', lwd=2)
title(main='Emptying reservoir fixed time steps (Heuns)')
grid()

# Number of function evaluations
num_eval_fixed = length(result_time_fixed)

# Error at each time step
analytical_comparison_fixed = abs(analytic_state_at_discrete_time_step_fixed - result_state_fixed)

# Root-mean-square deviation
RMSD = sqrt(sum(analytical_comparison_fixed^2)/length(analytical_comparison_fixed))

# Print the RMSE, number of runs, and number of evaluations
print(paste("The root mean square deviation for the fixed Heuns scheme is:", RMSD))
print(paste("The number of runs for the fixed Heuns scheme is:", simulation_results_fixed$runs))
print(paste("The number of evaluations for the fixed Heuns scheme is:", num_eval_fixed))
```

Fixed Time Stepping (Euler)
```{R}
begin_time = 0 # [s]
end_time = 50 # [s]
dt_start   = 3 # [s]
initial_state = 3 # [m]
A = 4.0 # [m2]
alpha = 1.5 
factor = 0.8 # [-]
tolerance = 0.01 

# Run the FIXED simulation
simulation_results_fixed = simulate_reservoir_fixed(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance,calculate_euler_forward_reservoir)

# Extract results for plotting and further analysis
result_time_fixed = simulation_results_fixed$time
result_state_fixed = simulation_results_fixed$state

# state of analytical solution to compare with numerical solution at every time step
analytic_state_at_discrete_time_step_fixed=initial_state * exp(-result_time_fixed*alpha/A)

# Plotting
plot(result_time_fixed, result_state_fixed,type='o', xlab="Time [s]", ylab="Water level [m]", col="blue")
lines(result_time_fixed, analytic_state_at_discrete_time_step_fixed, col='grey', lwd=2)
title(main='Emptying reservoir fixed time steps (Euler forward)')
grid()

# Number of function evaluations
num_eval_fixed = length(result_time_fixed)

# Error at each time step
analytical_comparison_fixed = abs(analytic_state_at_discrete_time_step_fixed - result_state_fixed)

# Root-mean-square deviation
RMSD = sqrt(sum(analytical_comparison_fixed^2)/length(analytical_comparison_fixed))

# Print the RMSE, number of runs, and number of evaluations
print(paste("The root mean square deviation for the fixed euler forward scheme is:", RMSD))
print(paste("The number of runs for the fixed euler forward scheme is:", simulation_results_fixed$runs))
print(paste("The number of evaluations for the fixed euler forward scheme is:", num_eval_fixed))

```

# Compare the fixed vs the variable schemes

Motivation: in order to compare the fixed vs variable schemes, we decided to consider the RMSE. The aim is to first calculate the error obtained from the variable scheme and the fixed scheme using the same starting dt values. This will result in a higher error for the fixed scheme. Then we find a new, smaller dt for the fixed scheme, such that the error of the fixed scheme is the same of that of the variable scheme. Now, the number of evaluations can be compared, since error is about the same. This will be implemented in the function below. 


```{R}
# Implement the error converging function
error_converging = error_decrease(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance,calculate_heuns_reservoir, calculate_euler_forward_reservoir, simulate_reservoir, simulate_reservoir_fixed)

# Run the simulation fixed simulation using dt_start = error_converging$dt_fixed from the function above
simulation_results_fixed_new_dt = simulate_reservoir_fixed(begin_time, end_time, error_converging$dt_fixed, initial_state, A, alpha, factor, tolerance,calculate_heuns_reservoir)

# Extract results for plotting and further analysis
result_time_fixed_new_dt = simulation_results_fixed_new_dt$time
result_state_fixed_new_dt = simulation_results_fixed_new_dt$state

# state of analytical solution to compare with numerical solution at every time step
analytic_state_at_discrete_time_step_fixed_new_dt=initial_state * exp(-result_time_fixed_new_dt*alpha/A)

# Number of function evaluations
num_eval_fixed_new_dt = length(result_time_fixed_new_dt)

# Error at each time step
analytical_comparison_fixed_new_dt = abs(analytic_state_at_discrete_time_step_fixed_new_dt - result_state_fixed_new_dt)

# Root-mean-square deviation
RMSD_new_dt = sqrt(sum(analytical_comparison_fixed_new_dt^2)/length(analytical_comparison_fixed_new_dt))

# Plot the new result 
plot(result_time_fixed_new_dt, result_state_fixed_new_dt,type='o', xlab="Time [s]", ylab="Water level [m]", col="blue")
lines(result_time_fixed_new_dt, analytic_state_at_discrete_time_step_fixed_new_dt, col='grey', lwd=2)
title(main='Emptying reservoir fixed time step (Heuns)')
grid()

# Print the important results 
print(paste("The RMSE for the fixed scheme (Heuns) with new dt is:", RMSD_new_dt))
print(paste("The number of runs for the fixed scheme (Heuns) with new dt is:", simulation_results_fixed_new_dt$runs))
print(paste("The number of evaluations for the fixed scheme (Heuns) with new dt is:", num_eval_fixed_new_dt))
```
```{R}

### ---------------------------  PART 3: EVALUATE THE GAINS (ERROR vs EVALUATIONS) ------------------- ###

# Functions used for fixed time-stepping: Heun's 
# Functions used for variable time-stepping: Heun's vs Euler 

# Create empty vectors to fill 
RMSD_fixed_comb = c()
RMSD_variable_comb = c()
evaluations_fixed_comb = c()
runs_variable_comb = c()
evaluations_variable_comb = c()
dt_start_comb = c()

# Evaluate gain: number of evaluations vs error 
# Within for loop run the gains function for different dt values to obtain different errors

for (i in 1:100){
  dt_start = i/10 #Create different dt_starting values to loop through 

gains_function = error_decrease(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance,calculate_heuns_reservoir, calculate_euler_forward_reservoir, simulate_reservoir, simulate_reservoir_fixed)

#Store values from each loop through the gain function in the empty vectors 
RMSD_fixed_comb = cbind(RMSD_fixed_comb, gains_function$RMSD_fixed)
RMSD_variable_comb = cbind(RMSD_variable_comb, gains_function$RMSD_variable)
evaluations_fixed_comb = cbind(evaluations_fixed_comb, gains_function$evaluations_fixed)
runs_variable_comb = cbind(runs_variable_comb, gains_function$runs_variable)
evaluations_variable_comb = cbind(evaluations_variable_comb, gains_function$evaluations_variable)
dt_start_comb = cbind(dt_start_comb, dt_start)
}

# Create figures showing the number of evaluations vs the RMSE (error)

# Figure with only the evaluations for the fixed and variable timestepping 
plot(evaluations_fixed_comb, RMSD_fixed_comb, type = "l", lwd = 3, xlim = c(0,300), xlab = "Number of evaluations", ylab = "Root Mean Squared Error (RMSE)", main = "Gain Evaluation")
lines(evaluations_variable_comb, RMSD_variable_comb, type = "l", lwd = 3, col="blue")
legend(225,0.0025, legend = c('Fixed', 'Variable'), col = c('black', 'blue'), lty = 1:1, lwd = 3)
grid()

# Figure with the number of runs also included for the variable timestepping
plot(evaluations_fixed_comb, RMSD_fixed_comb, type = "l", lwd = 3, xlim = c(0,300), xlab = "Number of evaluations", ylab = "Root Mean Squared Error (RMSE)", main = "Gain Evaluation")
lines(evaluations_variable_comb, RMSD_variable_comb, type = "l", lwd = 3, col="blue")
lines(runs_variable_comb, RMSD_variable_comb, col="red", type = "l", lwd = 3)
legend(200,0.0028, legend = c('Fixed evaluations', 'Variable evaluations', 'Variable runs'), col = c('black', 'blue', 'red'), lty = 1:1, lwd = 3)
grid()
```


#### Fixed Time-Stepping Simulation
We run 12 simulations with fixed time steps varying from 1/8 to 12/8:
```{R}
# Discretisation Parameters
begin_time <- 0
end_time <- 50
dt_start <- 10
initial_state <- 3

# Reservoir Parameters
A <- 4.0
alpha <- 1.5


# Running Simulation
# Vectors for storing results
num_eval_comb_fix <- c()
RMSD_comb_fix <- c()

for (i in 1:12) {
  dt <- i / 8

  # Simulation Initialisation
  time <- begin_time
  result_state <- c(initial_state)
  result_time <- c(time)
  current_state <- initial_state

  while (time < end_time) {
    current_state <- calculate_euler_forward_reservoir(current_state, dt, A, alpha)
    result_state <- c(result_state, current_state)
    time <- time + dt
    result_time <- c(result_time, time)
  }

  # Analytical Solution
  time.sequence <- seq(begin_time, end_time, by = 0.1)
  analyt_state <- initial_state * exp(-time.sequence * alpha / A)
  analyt_state_compare <- initial_state * exp(-result_time * alpha / A)

  # Plotting Result
  plot(result_time, result_state, type = "o", xlab = "time", ylab = "state")
  lines(time.sequence, analyt_state, col = "grey", lwd = 2)
  title(main = "Emptying reservoir")
  grid()

  # Number of function evaluations
  num_eval <- length(result_time)
  num_eval_comb_fix <- cbind(num_eval_comb_fix, num_eval)
  # print(paste("Number of function evaluations:", num_eval))

  # Root-mean-square deviation
  RMSD_fix <- sqrt(mean((analyt_state_compare - result_state)^2))
  RMSD_comb_fix <- cbind(RMSD_comb_fix, RMSD_fix)
}

plot(num_eval_comb_fix, RMSD_comb_fix)
```

#### Simulation with Varying Starting dt
```{r}
# Vectors for storing results
num_eval_comb_var <- c()
RMSD_comb_var <- c()
iterations_comb <- c()

# Discretisation Parameters
begin_time <- 0
end_time <- 50
initial_state <- 3

# Reservoir Parameters
A <- 4.0
alpha <- 1.5

# Vary starting dt
for (i in 1:20) {
  tolerance <- 10^-2
  factor <- 0.9
  dt_start <- i / 4

  simulation_results <- simulate_reservoir(
    begin_time, end_time, dt_start,
    initial_state, A, alpha, factor,
    tolerance, calculate_heuns_reservoir,
    calculate_euler_forward_reservoir
  )

  # Analytical solution
  time_sequence <- seq(begin_time, end_time, by = 0.1)
  analyt_state <- initial_state * exp(-time_sequence * alpha / A)
  analyt_state_compare <- initial_state * exp(-simulation_results$time * alpha / A)

  # Number of function evaluations and iterations
  num_eval <- length(simulation_results$time)
  num_eval_comb_var <- cbind(num_eval_comb_var, num_eval)
  iterations_comb <- cbind(iterations_comb, simulation_results$iterations)

  # Root-mean-square deviation
  RMSD_var <- sqrt(mean((analyt_state_compare - simulation_results$state)^2))
  RMSD_comb_var <- cbind(RMSD_comb_var, RMSD_var)
}

# Plotting Result
plot(num_eval_comb_fix, RMSD_comb_fix, col = "red", xlab = "Number of evaluations", ylab = "RMSD", ylim = c(0, 0.2), xlim = c(0, 200))
points(num_eval_comb_var, RMSD_comb_var, col = "blue")

plot(num_eval_comb_fix, RMSD_comb_fix, type = "l", col = "red", xlab = "Number of evaluations", ylab = "RMSD", ylim = c(0, 0.2), xlim = c(0, 600))
points(iterations_comb, RMSD_comb_var, type = "l", col = "blue")
```


# Analysis of the CK Scheme: Evaluating ME and RMSE against Number of Evaluations
This section analyzes the performance of the Cash-Karp (CK) scheme in the reservoir simulation. We aim to understand how the Mean Error (ME) and Root Mean Square Error (RMSE) vary with the number of evaluations under different tolerance settings.

```{r}
# Vectors for storing results
num_eval_comb <- c()
ME_comb <- c()
RMSD_comb <- c()

# Discretisation Parameters
begin_time <- 0
end_time <- 50
initial_state <- 3

# Reservoir Parameters
A <- 4.0
alpha <- 1.5

dt_start <- 3

# Vary tolerance
for (i in 1:12) {
  tolerance <- 10^-(i / 2)
  factor <- 0.9

  simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_rk4_reservoir, calculate_rk5_reservoir)

  # Analytical solution
  time_sequence <- seq(begin_time, end_time, by = 0.1)
  analyt_state <- initial_state * exp(-time_sequence * alpha / A)
  analyt_state_compare <- initial_state * exp(-simulation_results$time * alpha / A)

  # Number of function evaluations
  num_eval <- length(simulation_results$time)
  # print(num_eval)


  ME <- mean(analyt_state_compare - simulation_results$state)
  RMSD <- sqrt(mean((analyt_state_compare - simulation_results$state)^2))

  num_eval_comb <- cbind(num_eval_comb, num_eval)
  ME_comb <- cbind(ME_comb, ME)
  RMSD_comb <- cbind(RMSD_comb, RMSD)
}


# Vectors for storing results
num_eval_comb_3 <- c()
ME_comb_3 <- c()
RMSD_comb_3 <- c()

dt_start <- 3

# Vary tolerance
for (i in 1:12) {
  tolerance <- 10^-(i / 2)
  factor <- 0.3

  simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_rk4_reservoir, calculate_rk5_reservoir)

  # Analytical solution
  time_sequence <- seq(begin_time, end_time, by = 0.1)
  analyt_state <- initial_state * exp(-time_sequence * alpha / A)
  analyt_state_compare <- initial_state * exp(-simulation_results$time * alpha / A)

  # Number of function evaluations
  num_eval <- length(simulation_results$time)
  # print(num_eval)

  ME <- mean(analyt_state_compare - simulation_results$state)
  RMSD <- sqrt(mean((analyt_state_compare - simulation_results$state)^2))

  num_eval_comb_3 <- cbind(num_eval_comb_3, num_eval)
  ME_comb_3 <- cbind(ME_comb_3, ME)
  RMSD_comb_3 <- cbind(RMSD_comb_3, RMSD)
}

# Plotting the result
plot(num_eval_comb, RMSD_comb, type = "p", col = "blue")
points(num_eval_comb, RMSD_comb_3, type = "p", col = "red")
```


Calculate total error in the entire domain of a simulation by comparing the areas under the numerical and analytical curves
```{R}
# Check and Install 'DescTools' Package
if (!"DescTools" %in% installed.packages()) {
  install.packages("DescTools", repos = "http://cran.us.r-project.org")
}
library(DescTools)

# Running the simulation
begin_time <- 0
end_time <- 50
dt_start <- 5
initial_state <- 3
factor <- 0.8
tolerance <- 0.01

A <- 4.0
alpha <- 1.5

simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

result_time <- simulation_results$time
result_state <- simulation_results$state

time_sequence <- seq(begin_time, end_time, by = 0.1)
analytic_state <- initial_state * exp(-time_sequence * alpha / A)
analytic_state_at_discrete_time_step <- initial_state * exp(-result_time * alpha / A)

# Calculate Area Under Curves
# For the numerical solution
area_under_numerical_curve <- AUC(result_time, result_state)

# For the analytical solution
area_under_analytical_curve <- AUC(time_sequence, analytic_state)

# Calculate Absolute and Percentage Difference
absolute_difference <- abs(area_under_numerical_curve - area_under_analytical_curve)
percentage_difference <- absolute_difference / area_under_analytical_curve * 100

# Output the differences and number of evaluations
print(paste0("The absolute and percentage difference between analytical and numerical solutions is: ", absolute_difference, " and ", percentage_difference, "%."))
# print(paste("The number of evaluations is", num_eval))
```
# Local Sensitivity Analysis
## Base Simulation

```{R}
# Define the starting parameters
begin_time = 0
end_time = 50
dt_start = 5
initial_state = 3
A = 4.0
alpha = 1.5
factor = 0.8
tolerance = 0.01

# Store the base values
base= list(initial_state = initial_state,A=A,alpha=alpha,tolerance=tolerance,factor=factor, dt_start = dt_start)
str(base)

# Define the time-range for the approx functions used later
approx_time = c(1:50)

# Run the base simulation
base_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

# Determine number of evaluation and runs needed 
base_num_eval = length(base_simulation_results$time)
print(paste("Number of evaluations for base=", base_num_eval))
print(paste("Number of runs for base=",base_simulation_results$runs))

# Approximate the function for late analysis 
approx_fun_base = approxfun(base_simulation_results$time,base_simulation_results$state)
approx_base_results = approx_fun_base(approx_time)

## ---------------- PART 4.2 Prepare for LSA:Define scale of variation and epsilon --------------- ##

# Define scale of variation for parameters
scale= list(initial_state = 0.05 *initial_state,
            A = 0.05 * A,
            alpha = 0.05 * alpha,
            tolerance = 1* tolerance,
            factor = 0.1*factor, 
            dt_start = 1 * dt_start)

#Define an epsilon value 
eps = 1e-3
```

## 4.3 LSA for each parameter

### 4.3.1 Initial state

Paramter type: Physical 

```{R}
# Pertrube parameter 
initial_state=base$initial_state+eps*base$initial_state

# Run model 
sens_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

## approximate function, using the timestpes defined earlier 
approx_fun_sens = approxfun(sens_simulation_results$time,sens_simulation_results$state)
approx_sens_results = approx_fun_sens(approx_time) # approx-time defined earlier 

## Capture number of runs and evaluations
num_eval_initial_state = length(sens_simulation_results$time)
print(paste("Number of evaluations for intial value=", num_eval_initial_state))
runs_intial_value = sens_simulation_results$runs
print(paste("Number of runs for initial value=",sens_simulation_results$runs))

# Reset the base values 
initial_state=base$initial_state

#Find the local slope for the states
dStates_dinitstate = (approx_sens_results - approx_base_results)/(eps*base$initial_state)

#Plot 
plot(approx_time,dStates_dinitstate,type="l",lwd=3,col="blue",main="d{state}/d{init.state}")
abline(h=0,col="red",lwd=3)
grid(col="black")
```


### 4.3.2 Alpha 

Paramter type: Physical 

```{R}
# Sensitivity of parameter
alpha=base$alpha+eps*base$alpha

# Run model 
sens_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

## approximate function
approx_fun_sens =approxfun(sens_simulation_results$time,sens_simulation_results$state)
approx_sens_results = approx_fun_sens(approx_time)

# Number of runs and evaluations
num_eval_alpha = length(sens_simulation_results$time)
print(paste("Number of evaluations for alpha =", num_eval_alpha))
runs_alpha = sens_simulation_results$runs
print(paste("Number of runs for alpha =",runs_alpha))

# Reset the base values 
alpha=base$alpha

#Find the local slope for the states
dStates_dAlpha  = (approx_sens_results - approx_base_results)/(eps*base$alpha)

#Plot 
plot(approx_time,dStates_dAlpha,type="l",lwd=3,col="blue",main="d{state}/d{Alpha}")
abline(h=0,col="red",lwd=3)
grid(col="black")
```


# --------------------------------- PART 4.3.3 AREA (A) ------------------------------------- #
# Paramter type: Physical 

```{R}
# Sensitivity of Area (A)
A=base$A+eps*base$A

# Run model 
sens_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

## approximate function
approx_fun_sens =approxfun(sens_simulation_results$time,sens_simulation_results$state)
approx_sens_results = approx_fun_sens(approx_time)

# Number of runs 
num_eval_A = length(sens_simulation_results$time)
print(paste("Number of evaluations for A=", num_eval_A ))
runs_A = sens_simulation_results$runs
print(paste("Number of runs for A =",runs_A))

# Reset the base values 
A=base$A

#Find the local slope for the states
dStates_dA = (approx_sens_results - approx_base_results)/(eps*base$A)

#Plot 
plot(approx_time,dStates_dA,type="l",lwd=3,col="blue",main="d{state}/d{A}")
abline(h=0,col="red",lwd=3)
grid(col="black")
```


### 4.3.4 Tolerance 

Parameter type: Numerical

```{R}
# Sensitivity of tolerance 
tolerance =base$tolerance +eps*base$tolerance 

# Run model 
sens_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

## approximate function
approx_fun_sens =approxfun(sens_simulation_results$time,sens_simulation_results$state)
approx_sens_results = approx_fun_sens(approx_time)

# Number of runs 
num_eval_tolerance = length(sens_simulation_results$time)
print(paste("Number of evaluations for A=", num_eval_tolerance))
runs_tolerance = sens_simulation_results$runs
print(paste("Number of runs for tolerance =",runs_tolerance))

# Reset the base values 
tolerance =base$tolerance 

#Find the local slope for the states
dStates_dTolerance = (approx_sens_results - approx_base_results)/(eps*base$tolerance )

#Plot 
plot(approx_time,dStates_dTolerance,type="l",lwd=3,col="blue",main="d{state}/d{tolerance}")
abline(h=0,col="red",lwd=3)
grid(col="black")

```

### 4.3.5 Factor 

Parameter type: Numerical

```{R}
# Sensitivity of factor
factor =base$factor + eps*base$factor 

# Run model 
sens_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

## approximate function
approx_fun_sens =approxfun(sens_simulation_results$time,sens_simulation_results$state)
approx_sens_results = approx_fun_sens(approx_time)

# Number of factor 
num_eval_factor = length(sens_simulation_results$time)
print(paste("Number of evaluations for factor=", num_eval_factor ))
runs_factor = sens_simulation_results$runs
print(paste("Number of runs for factor =",runs_factor))

# Reset the base values 
factor =base$factor 

#Find the local slope for the states
dStates_dfactor = (approx_sens_results - approx_base_results)/(eps*base$factor)

#Plot 
plot(approx_time,dStates_dfactor,type="l",lwd=3,col="blue",main="d{state}/d{factor}")
abline(h=0,col="red",lwd=3)
grid(col="black")

```

### 4.3.6 dt start

Parameter type: Numerical

```{R}
# Sensitivity of init.state
dt_start =base$dt_start +eps*base$dt_start 

# Run model 
sens_simulation_results = simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

## approximate function
approx_fun_sens =approxfun(sens_simulation_results$time,sens_simulation_results$state)
approx_sens_results = approx_fun_sens(approx_time)

# Number of runs 
num_eval_dt = length(sens_simulation_results$time)
print(paste("Number of evaluations for dt=", num_eval_dt ))
runs_dt = sens_simulation_results$runs
print(paste("Number of runs for dt =",runs_dt))

# Reset the base values 
dt_start= base$dt_start  

#Find the local slope for the states
dStates_dDt_start  = (approx_sens_results - approx_base_results)/(eps*base$dt_start)

#Plot 
plot(approx_time,dStates_dDt_start,type="l",lwd=3,col="blue",main="d{state}/d{dt_start}")
abline(h=0,col="red",lwd=3)
grid(col="black")

```

## 4.4 Calculate variance and total scale of variation

```{r}
# Variance per parameter
varState.initial_state = (scale$initial_state*dStates_dinitstate)^2
varState.alpha = (scale$alpha*dStates_dAlpha)^2
varState.A  = (scale$A*dStates_dA)^2
varState.tolerance= (scale$tolerance*dStates_dTolerance)^2
varState.factor = (scale$factor*dStates_dfactor)^2
varState.dt_start = (scale$dt_start*dStates_dDt_start)^2

# Separate physical and numerical and total parameters
varStateTotPhysical = varState.initial_state + varState.alpha + varState.A
varStateTotNumerical = varState.tolerance+ varState.factor + varState.dt_start
varStateTotal = varState.initial_state + varState.alpha + varState.A + varState.tolerance+ varState.factor + varState.dt_start

# Check that total adds up to 1 for each timestep
total = varState.initial_state/varStateTotal + varState.alpha/varStateTotal + varState.A/varStateTotal + varState.tolerance/varStateTotal + varState.factor/varStateTotal + varState.dt_start/varStateTotal

#Plot the scale of variation of the states over the whole domain:
plot(approx_time,sqrt(varStateTotPhysical),type="l",col="blue",lwd=3,
     ylab="standard deviation [m]",xlab="Time [s]",main="Total scale of variation of physical parameters")
grid(col="black")

plot(approx_time,sqrt(varStateTotNumerical),type="l",col="blue",lwd=3,
     ylab="standard deviation [m]",xlab="Time [s]",main="Total scale of variation of numerical parameters")
grid(col="black")

plot(approx_time,sqrt(varStateTotal),type="l",col="blue",lwd=3,
     ylab="standard deviation [m]",xlab="Time [s]",main="Total scale of variation of all parameters")
grid(col="black")
```

## 4.5 Plot relative contribution to variance of each parameter
### 4.5.1 Physical parameters 
```{R}
## Plot stacked bar charts 
library(ggplot2)
# create a data set
parameters <- (c(rep("Initial state", length(approx_time)), rep("Alpha", length(approx_time)), rep("A", length(approx_time))))
value <- c(abs(varState.initial_state/varStateTotPhysical), abs(varState.alpha/varStateTotPhysical), abs(varState.A/varStateTotPhysical))
data <- data.frame(approx_time,parameters,value)
# Stacked bar chart 
ggplot(data, aes(fill=parameters, y=value, x=approx_time)) + 
    geom_bar(position="stack", stat="identity", width=0.8) + ggtitle("Relative contribution to variance for physical parameters") + xlab("Time [s]") + ylab("Relative contribution to variance [-]")
```


### 4.5.2 Numerical parameters

```{R}
## Plot with barchart
library(ggplot2)
# create a dataset
parameters <- (c(rep("tolerance", length(approx_time)), rep("factor", length(approx_time)), rep("dt start", length(approx_time))))
value <- c(abs(varState.tolerance/varStateTotNumerical), abs(varState.factor/varStateTotNumerical), abs(varState.dt_start/varStateTotNumerical))
data <- data.frame(approx_time,parameters,value)
# Stacked
ggplot(data, aes(fill=parameters, y=value, x=approx_time)) + 
    geom_bar(position="stack", stat="identity", width=0.8) + ggtitle("Relative contribution to variance for numerical parameters") + xlab("Time [s]") + ylab("Relative contribution to variance [-]")
```

### PART 4.5.3 All parameters
```{R}
## Plot with barchart
library(ggplot2)
# create a dataset
parameters<- (c(rep("initial state", length(approx_time)), rep("A", length(approx_time)), rep("alpha", length(approx_time)), rep("tolerance", length(approx_time)), rep("factor", length(approx_time)), rep("dt start", length(approx_time))))
value <- c(varState.initial_state/varStateTotal, varState.A/varStateTotal, varState.alpha/varStateTotal, varState.tolerance/varStateTotal, varState.factor/varStateTotal, varState.dt_start/varStateTotal)
data <- data.frame(approx_time,parameters,value)
# Stacked
ggplot(data, aes(fill=parameters, y=value, x=approx_time)) + 
    geom_bar(position="stack", stat="identity", width=0.8) + ggtitle("Relative contribution to variance for all parameters") + xlab("Time [s]") + ylab("Relative contribution to variance [-]")


total = varState.initial_state/varStateTotal + varState.alpha/varStateTotal + varState.A/varStateTotal + varState.tolerance/varStateTotal + varState.factor/varStateTotal + varState.dt_start/varStateTotal

```

## 5 Global sensitivity analysis
This section performs a global sensitivity analysis on our reservoir simulation model to better understand the influence of both physical and numerical parameters on the model's output. We use Latin Hypercube Sampling (LHS) to efficiently explore the parameter space.
```{R}
# Load function to generate samples using LHS
source("samplehelpers.R")
```

### 5.1 Parameter Setup
We define the base values and scales for physical and numerical parameters:
```{R}
# Base Values
begin_time <- 0
end_time <- 50
dt_start <- 5
initial_state <- 3
A <- 4.0
alpha <- 1.5
factor <- 0.8
tolerance <- 0.01

# Base and scale for physical and numerical parameters
base_physical_global <- list(initial_state = initial_state, A = A, alpha = alpha)
scale_physical_global <- list(initial_state = 0.05 * initial_state, A = 0.05 * A, alpha = 0.05 * alpha)
base_numerical_global <- list(tolerance = tolerance, factor = factor, dt_start = dt_start)
scale_numerical_global <- list(tolerance = 1 * tolerance, factor = 0.1 * factor, dt_start = 1 * dt_start)
base_both_global <- list(initial_state = initial_state, A = A, alpha = alpha, tolerance = tolerance, factor = factor, dt_start = dt_start)
scale_both_global <- list(initial_state = 0.05 * initial_state, A = 0.05 * A, alpha = 0.05 * alpha, tolerance = 1 * tolerance, factor = 0.1 * factor, dt_start = 1 * dt_start)
scale_numerical_global <- list(tolerance = 1 * tolerance, factor = 0.1 * factor, dt_start = 1 * dt_start)

physical_names_global <- names(base_physical_global)
physical_means_global <- unlist(base_physical_global)
physical_sds_global <- unlist(scale_physical_global)

numerical_names_global <- names(base_numerical_global)
numerical_means_global <- unlist(base_numerical_global)
numerical_sds_global <- unlist(scale_numerical_global)

both_names_global <- names(base_both_global)
both_means_global <- unlist(base_both_global)
both_sds_global <- unlist(scale_both_global)

# Define ranges for physical and numerical parameters
physical_lower_global <- c(2, 3.5, 1)
physical_upper_global <- c(4, 4.5, 2)

numerical_lower_global <- c(0.0005, 0.5, 0.01)
numerical_upper_global <- c(0.05, 0.99, 20)

both_lower_global <- c(2, 3.5, 1, 0.0005, 0.5, 0.01)
both_upper_global <- c(4, 4.5, 2, 0.05, 0.99, 20)

# Using Gaussian LHS to generate samples within the specified ranges
# Sample size and random seed
samplesize <- 1000
set.seed(237)

physical_sample_global <- GaussianLHS(samplesize, physical_means_global, physical_sds_global, physical_names_global, physical_lower_global, physical_upper_global)

numerical_sample_global <- GaussianLHS(samplesize, numerical_means_global, numerical_sds_global, numerical_names_global, numerical_lower_global, numerical_upper_global)

both_sample_global <- GaussianLHS(samplesize, both_means_global, both_sds_global, both_names_global, both_lower_global, both_upper_global)

# plot(physical_sample_global, cex = 0.4)
# plot(numerical_sample_global, cex = 0.4)
# plot(both_sample_global, cex = 0.4)

# Plotting histograms of samples
old.par <- par(no.readonly = TRUE)
par(mfrow = c(2, 3))
hist(physical_sample_global[, "initial_state"], main = "", col = "lightblue", prob = TRUE)
rug(physical_sample_global[, "initial_state"], col = "red")
lines(density(physical_sample_global[, "initial_state"]), col = "red", lwd = 2)

hist(physical_sample_global[, "A"], main = "", col = "lightblue", prob = TRUE)
rug(physical_sample_global[, "A"], col = "red")
lines(density(physical_sample_global[, "A"]), col = "red", lwd = 2)

hist(physical_sample_global[, "alpha"], main = "", col = "lightblue", prob = TRUE)
rug(physical_sample_global[, "alpha"], col = "red")
lines(density(physical_sample_global[, "alpha"]), col = "red", lwd = 2)

hist(numerical_sample_global[, "tolerance"], main = "", col = "lightblue", prob = TRUE)
rug(numerical_sample_global[, "tolerance"], col = "red")
lines(density(numerical_sample_global[, "tolerance"]), col = "red", lwd = 2)

hist(numerical_sample_global[, "factor"], main = "", col = "lightblue", prob = TRUE)
rug(numerical_sample_global[, "factor"], col = "red")
lines(density(numerical_sample_global[, "factor"]), col = "red", lwd = 2)

hist(numerical_sample_global[, "dt_start"], main = "", col = "lightblue", prob = TRUE)
rug(numerical_sample_global[, "dt_start"], col = "red")
lines(density(numerical_sample_global[, "dt_start"]), col = "red", lwd = 2)
```

### Kolmogorov–Smirnov test to decide sample size
It is quite difficult to conduct the k-s test with vector (time series) as the model output so we decided to use a sample size of 10000.
```{R, eval = FALSE}
# # Define the parameters
# begin_time <- 0
# end_time <- 50
# initial_state <- base_physical_global$initial_state
# A <- base_physical_global$A
# alpha <- base_physical_global$alpha
# tolerance <- base_numerical_global$tolerance
# dt_start <- base_numerical_global$dt_start
# factor <- base_numerical_global$factor
# 
# points_for_evaluation <- c(0:50)
# 
# samplesize_old <- 0
# 
# repeat {
#   samplesize_old <- samplesize_old + 100
#   samplesize_new <- samplesize_old + 100
# 
#   both_sample_global_old <- GaussianLHS(samplesize_old, both_means_global, both_sds_global, both_names_global, both_lower_global, both_upper_global)
#   both_sample_global_new <- GaussianLHS(samplesize_new, both_means_global, both_sds_global, both_names_global, both_lower_global, both_upper_global)
# 
#   simulation_results_approx_old <- matrix(0, ncol = length(points_for_evaluation), nrow = 0)
# 
#   # For-loop through the old parameter sample
#   for (i in 1:nrow(both_sample_global_old))
#   {
#     initial_state <- both_sample_global_old[i, "initial_state"]
#     A <- both_sample_global_old[i, "A"]
#     alpha <- both_sample_global_old[i, "alpha"]
#     tolerance <- both_sample_global_old[i, "tolerance"]
#     factor <- both_sample_global_old[i, "factor"]
#     dt_start <- both_sample_global_old[i, "dt_start"]
# 
#     # Run the simulation
#     simulation_results_old <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)
# 
#      # Extract results for plotting and further analysis
#   result_time_old <- simulation_results_old$time
#   result_state_old <- simulation_results_old$state
# 
#   # Use linear interpolation to approximate the value of the results at certain points for evaluation
#   linear_interpolation_old <- approxfun(result_time_old, result_state_old)
#   simulation_results_approx_old <- rbind(simulation_results_approx_old, linear_interpolation_old(points_for_evaluation))
# 
#   }
#   simulation_results_approx_new <- matrix(0, ncol = length(points_for_evaluation), nrow = 0)
# 
#   # For-loop through the new parameter sample
#   for (i in 1:nrow(both_sample_global_new))
#   {
#     initial_state <- both_sample_global_new[i, "initial_state"]
#     A <- both_sample_global_new[i, "A"]
#     alpha <- both_sample_global_new[i, "alpha"]
#     tolerance <- both_sample_global_new[i, "tolerance"]
#     factor <- both_sample_global_new[i, "factor"]
#     dt_start <- both_sample_global_new[i, "dt_start"]
# 
#     # Run the simulation
#     simulation_results_new <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)
# 
#     # Extract results for plotting and further analysis
#   result_time_new <- simulation_results_new$time
#   result_state_new <- simulation_results_new$state
# 
#   # Use linear interpolation to approximate the value of the results at certain points for evaluation
#   linear_interpolation_new <- approxfun(result_time_new, result_state_new)
#   simulation_results_approx_new <- rbind(simulation_results_approx_new, linear_interpolation_new(points_for_evaluation))
#   }
#   
#   
#   significant <- FALSE
# p_val <- numeric(length(points_for_evaluation))
# 
# # For each time step conduct the Kolmogorov–Smirnov test  
# for (i in seq_along(points_for_evaluation)) {
#     test_result <- ks.test(simulation_results_approx_old[,i], simulation_results_approx_new[,i])
#     
#     # Store the p-value of each time step
#     p_val[i] <- test_result$p.value
# }
# 
# # Use mean p-value for overall significance test
# mean_p_val <- mean(p_val)
#     if (mean_p_val > 0.99) {
#         significant <- TRUE
# }
# 
# # Print information while running
# print(paste("Sample sizes - Old:", samplesize_old, "New:", samplesize_new, "Mean P-value:", mean_p_val))
# 
# # Break the loop if any of the tests are significant
# if (significant) {
#     print("Breaking loop due to significant KS test")
#     break
# }
# }
# print(samplesize_old)
```


### GSA for physical parameters
```{R}
state_physical_global <- matrix(0, ncol = length(result_time), nrow = 0)
time_physical_global <- matrix(0, ncol = length(result_time), nrow = 0)

# Define the parameters
begin_time <- 0
end_time <- 50
initial_state <- base_physical_global$initial_state
A <- base_physical_global$A
alpha <- base_physical_global$alpha
tolerance <- base_numerical_global$tolerance
dt_start <- base_numerical_global$dt_start
factor <- base_numerical_global$factor

# Points to evaluate
points_for_evaluation <- c(0:50)

simulation_results_approx <- matrix(0, ncol = length(points_for_evaluation), nrow = 0)

# Start the for-loop through the parameter sample
for (i in 1:nrow(physical_sample_global))
{
  initial_state <- physical_sample_global[i, "initial_state"]
  A <- physical_sample_global[i, "A"]
  alpha <- physical_sample_global[i, "alpha"]

  # Run the simulation
  simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

  # Extract results for plotting and further analysis
  result_time <- simulation_results$time
  result_state <- simulation_results$state

  # Use linear interpolation to approximate the value of the results at certain points for evaluation
  linear_interpolation <- approxfun(result_time, result_state)
  simulation_results_approx <- rbind(simulation_results_approx, linear_interpolation(points_for_evaluation))

  # Analytical solution
  time_sequence <- seq(begin_time, end_time, by = 0.1)
  analytic_state <- initial_state * exp(-time_sequence * alpha / A)

  # Water Level of analytical solution to compare with numerical solution at every time step
  analytic_state_at_discrete_time_step <- initial_state * exp(-result_time * alpha / A)

  # Number of function evaluations
  num_eval <- length(result_time)

  # Error at each time step
  analytical_comparison <- abs(analytic_state_at_discrete_time_step - result_state)

  # Root-mean-square deviation
  # RMSD = sqrt(sum(analytical_comparison^2)/length(analytical_comparison))
  # print(paste("The root mean square deviation is:", RMSD))
  # print(paste("The number of evaluations is", num_eval))
}

# Check and Install 'matrixStats' Package
if (!"matrixStats" %in% installed.packages()) {
  install.packages("matrixStats")
}
library(matrixStats)

# Plotting the result
matplot(t(time_physical_global), t(state_physical_global), type = "l", main = "States for all parameter sets", ylab = "water level")
matplot(points_for_evaluation, t(simulation_results_approx), type = "l", main = "States for all parameter sets", ylab = "water level")
```

```{R}
# Check and Install 'gifski' Package to combine plots into animations after knitting to html
if (!"gifski" %in% installed.packages()) {
  install.packages("gifski", repos = "http://cran.us.r-project.org")
}
library(gifski)
```

```{R, animation.hook="gifski", interval = 0.3}
# Plotting conditional expectation at different time steps
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], physical_sample_global)
  plot(MPsample[, "initial_state"], MPsample[, "M"], main = paste("Value of initial state versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondinitial_state <- linloess(M ~ initial_state, data = MPsample)
  points(MPsample[, "initial_state"], Mcondinitial_state, pch = 20, col = "red")
}
```


```{R, animation.hook="gifski", interval = 0.3}
# Plotting conditional expectation at different time steps
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], physical_sample_global)
  plot(MPsample[, "A"], MPsample[, "M"], main = paste("Value of area versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  McondA <- linloess(M ~ A, data = MPsample)
  points(MPsample[, "A"], McondA, pch = 20, col = "red")
}
```


```{R, animation.hook="gifski", interval = 0.3}
# Plotting conditional expectation at different time steps
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], physical_sample_global)
  plot(MPsample[, "alpha"], MPsample[, "M"], main = paste("Value of alpha versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondalpha <- linloess(M ~ alpha, data = MPsample)
  points(MPsample[, "alpha"], Mcondalpha, pch = 20, col = "red")
}
```


```{R, animation.hook="gifski", interval = 0.3}
# Plotting variance contribution of parameters to the model at different time steps as pie charts
variance_initial_state <- c()
variance_A <- c()
variance_alpha <- c()
variance_model <- c()

for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], physical_sample_global)
  VARM <- var(simulation_results_approx[, i])
  variance_model <- c(variance_model, VARM)
  SDM <- sd(simulation_results_approx[, i])
  ANOVA1 <- sample.vardecomp(MPsample)
  variance_initial_state <- c(variance_initial_state, ANOVA1[[1]])
  variance_A <- c(variance_A, ANOVA1[[2]])
  variance_alpha <- c(variance_alpha, ANOVA1[[3]])

  added_var <- 0
  for (j in c(1:length(ANOVA1))) {
    added_var <- added_var + ANOVA1[[j]]
  }
  pie(ANOVA1,
    main = paste(
      "Variance of M =", VARM, "at t =", i - 1,
      "\nRemaining variance is", VARM - added_var
    ),
    col = rainbow(5),
    radius = 1
  )
}
```


```{R}
# Check and Install 'ggplot2' Package for plotting
if (!"ggplot2" %in% installed.packages()) {
  install.packages("ggplot2", repos = "http://cran.us.r-project.org")
}
library(ggplot2)

# Plotting variance contribution of parameters to the model at different time steps as a bar chart
# Create a dataset
parameters <- (c(rep("initial_state", length(points_for_evaluation) - 1), rep("A", length(points_for_evaluation) - 1), rep("alpha", length(points_for_evaluation) - 1), rep("unexplained_variance", length(points_for_evaluation) - 1)))
variance <- c(abs(variance_initial_state / variance_model), abs(variance_A / variance_model), abs(variance_alpha / variance_model), abs((variance_model - variance_initial_state - variance_A - variance_alpha) / variance_model))
time <- c(1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1))
data <- data.frame(time, parameters, variance)

# Stacked Barchart
data$parameters <- factor(data$parameters, levels = c("unexplained_variance", "initial_state", "A", "alpha"))

# png("gsa_physical_variance.png", width=900, height=450)
plot <- ggplot(data, aes(fill = parameters, y = variance, x = time)) +
  geom_bar(position = "stack", stat = "identity", linewidth = 0.3) +
  ggtitle("Relative contribution to variance for physical parameters") +
  xlab("Time") +
  ylab("Relative contribution to variance")
print(plot)
# dev.off()
#
```

### GSA for numerical parameters
```{R}
state_numerical_global <- matrix(0, ncol = length(result_time), nrow = 0)
time_numerical_global <- matrix(0, ncol = length(result_time), nrow = 0)

# Define the parameters
begin_time <- 0
end_time <- 50
initial_state <- base_physical_global$initial_state
A <- base_physical_global$A
alpha <- base_physical_global$alpha

tolerance <- base_numerical_global$tolerance
factor <- base_numerical_global$factor
dt_start <- base_numerical_global$dt_start

# point to evaluate
points_for_evaluation <- c(0:50)

simulation_results_approx <- matrix(0, ncol = length(points_for_evaluation), nrow = 0)

# start the for-loop through the parameter sample
for (i in 1:nrow(numerical_sample_global))
{
  tolerance <- numerical_sample_global[i, "tolerance"]
  factor <- numerical_sample_global[i, "factor"]
  dt_start <- numerical_sample_global[i, "dt_start"]

  # Run the simulation
  simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_heuns_reservoir, calculate_euler_forward_reservoir)

  # Extract results for plotting and further analysis
  result_time <- simulation_results$time
  result_state <- simulation_results$state

  linear_interpolation <- approxfun(result_time, result_state)
  simulation_results_approx <- rbind(simulation_results_approx, linear_interpolation(points_for_evaluation))

  # Analytical solution
  time_sequence <- seq(begin_time, end_time, by = 0.1)
  analytic_state <- initial_state * exp(-time_sequence * alpha / A)

  # state of analytical solution to compare with numerical solution at every time step
  analytic_state_at_discrete_time_step <- initial_state * exp(-result_time * alpha / A)

  # Number of function evaluations
  num_eval <- length(result_time)

  # Error at each time step
  analytical_comparison <- abs(analytic_state_at_discrete_time_step - result_state)

  # Root-mean-square deviation
  # RMSD = sqrt(sum(analytical_comparison^2)/length(analytical_comparison))
  # print(paste("The root mean square deviation is:", RMSD))
  # print(paste("The number of evaluations is", num_eval))
}

# Plotting the result
matplot(t(time_numerical_global), t(state_numerical_global), type = "l", main = "States for all parameter sets", ylab = "water level")
matplot(points_for_evaluation, t(simulation_results_approx), type = "l", main = "States for all parameter sets", ylab = "water level")
```

```{R, animation.hook="gifski", interval = 0.3}
# Plotting conditional expectation at different time steps
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], numerical_sample_global)
  plot(MPsample[, "tolerance"], MPsample[, "M"], main = paste("Value of tolerance versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondtolerance <- linloess(M ~ tolerance, data = MPsample)
  points(MPsample[, "tolerance"], Mcondtolerance, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
# Plotting conditional expectation at different time steps
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], numerical_sample_global)
  plot(MPsample[, "factor"], MPsample[, "M"], main = paste("Value of factor versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondfactor <- linloess(M ~ factor, data = MPsample)
  points(MPsample[, "factor"], Mcondfactor, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
# Plotting conditional expectation at different time steps
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], numerical_sample_global)
  plot(MPsample[, "dt_start"], MPsample[, "M"], main = paste("Value of starting dt versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mconddt_start <- linloess(M ~ dt_start, data = MPsample)
  points(MPsample[, "dt_start"], Mconddt_start, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
# Plotting variance contribution of parameters to the model at different time steps as pie charts
variance_tolerance <- c()
variance_factor <- c()
variance_dt_start <- c()
variance_model <- c()

for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], numerical_sample_global)
  VARM <- var(simulation_results_approx[, i])
  variance_model <- c(variance_model, VARM)
  SDM <- sd(simulation_results_approx[, i])
  ANOVA1 <- sample.vardecomp(MPsample)
  variance_tolerance <- c(variance_tolerance, ANOVA1[[1]])
  variance_factor <- c(variance_factor, ANOVA1[[2]])
  variance_dt_start <- c(variance_dt_start, ANOVA1[[3]])

  added_var <- 0
  for (j in c(1:length(ANOVA1))) {
    added_var <- added_var + ANOVA1[[j]]
  }
  pie(ANOVA1,
    main = paste(
      "Variance of M =", VARM, "at t =", i - 1,
      "\nRemaining variance is", VARM - added_var
    ),
    col = rainbow(5),
    radius = 1
  )
}
```

```{R}
# Plotting variance contribution of parameters to the model at different time steps as a bar chart
# create a dataset
parameters <- (c(rep("tolerance", length(points_for_evaluation) - 1), rep("factor", length(points_for_evaluation) - 1), rep("dt_start", length(points_for_evaluation) - 1), rep("unexplained_variance", length(points_for_evaluation) - 1)))
variance <- c(abs(variance_tolerance / variance_model), abs(variance_factor / variance_model), abs(variance_dt_start / variance_model), abs((variance_model - variance_tolerance - variance_factor - variance_dt_start) / variance_model))
time <- c(1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1))
data <- data.frame(time, parameters, variance)

data$parameters <- factor(data$parameters, levels = c("unexplained_variance", "tolerance", "factor", "dt_start"))

# Stacked
# png("gsa_numerical_variance.png", width=900, height=450)
plot <- ggplot(data, aes(fill = parameters, y = variance, x = time)) +
  geom_bar(position = "stack", stat = "identity", linewidth = 0.3) +
  ggtitle("Relative contribution to variance for numerical parameters") +
  xlab("Time") +
  ylab("Relative contribution to variance")
print(plot)
# dev.off()
```

### GSA for both physical and numerical parameters in the same model
```{R}
state_both_global <- matrix(0, ncol = length(result_time), nrow = 0)
time_both_global <- matrix(0, ncol = length(result_time), nrow = 0)

# Define the parameters
begin_time <- 0
end_time <- 50
initial_state <- base_physical_global$initial_state
A <- base_physical_global$A
alpha <- base_physical_global$alpha
tolerance <- base_numerical_global$tolerance
dt_start <- base_numerical_global$dt_start
factor <- base_numerical_global$factor

# point to evaluate
points_for_evaluation <- c(0:50)

simulation_results_approx <- matrix(0, ncol = length(points_for_evaluation), nrow = 0)

# start the for-loop through the parameter sample
for (i in 1:nrow(both_sample_global))
{
  initial_state <- both_sample_global[i, "initial_state"]
  A <- both_sample_global[i, "A"]
  alpha <- both_sample_global[i, "alpha"]
  tolerance <- both_sample_global[i, "tolerance"]
  factor <- both_sample_global[i, "factor"]
  dt_start <- both_sample_global[i, "dt_start"]

  # Run the simulation
  simulation_results <- simulate_reservoir(begin_time, end_time, dt_start, initial_state, A, alpha, factor, tolerance, calculate_rk4_reservoir, calculate_rk5_reservoir)

  # Extract results for plotting and further analysis
  result_time <- simulation_results$time
  result_state <- simulation_results$state

  linear_interpolation <- approxfun(result_time, result_state)
  simulation_results_approx <- rbind(simulation_results_approx, linear_interpolation(points_for_evaluation))

  # Analytical solution
  time_sequence <- seq(begin_time, end_time, by = 0.1)
  analytic_state <- initial_state * exp(-time_sequence * alpha / A)

  # state of analytical solution to compare with numerical solution at every time step
  analytic_state_at_discrete_time_step <- initial_state * exp(-result_time * alpha / A)

  # Number of function evaluations
  num_eval <- length(result_time)

  # Error at each time step
  analytical_comparison <- abs(analytic_state_at_discrete_time_step - result_state)

  # Root-mean-square deviation
  # RMSD = sqrt(sum(analytical_comparison^2)/length(analytical_comparison))
  # print(paste("The root mean square deviation is:", RMSD))
  # print(paste("The number of evaluations is", num_eval))
}

# Plotting the result
matplot(t(time_both_global), t(state_both_global), type = "l", main = "States for all parameter sets", ylab = "water level")
matplot(points_for_evaluation, t(simulation_results_approx), type = "l", main = "States for all parameter sets", ylab = "water level")
```

```{R, animation.hook="gifski", interval = 0.3}
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  plot(MPsample[, "initial_state"], MPsample[, "M"], main = paste("Value of initial state versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondinitial_state <- linloess(M ~ initial_state, data = MPsample)
  points(MPsample[, "initial_state"], Mcondinitial_state, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  plot(MPsample[, "A"], MPsample[, "M"], main = paste("Value of area versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  McondA <- linloess(M ~ A, data = MPsample)
  points(MPsample[, "A"], McondA, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  plot(MPsample[, "alpha"], MPsample[, "M"], main = paste("Value of alpha versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondalpha <- linloess(M ~ alpha, data = MPsample)
  points(MPsample[, "alpha"], Mcondalpha, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  plot(MPsample[, "tolerance"], MPsample[, "M"], main = paste("Value of tolerance versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondtolerance <- linloess(M ~ tolerance, data = MPsample)
  points(MPsample[, "tolerance"], Mcondtolerance, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  plot(MPsample[, "factor"], MPsample[, "M"], main = paste("Value of factor versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mcondfactor <- linloess(M ~ factor, data = MPsample)
  points(MPsample[, "factor"], Mcondfactor, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  plot(MPsample[, "dt_start"], MPsample[, "M"], main = paste("Value of starting dt versus model results \nwith conditional expectation at t =", i - 1), ylim = c(0, 3))
  Mconddt_start <- linloess(M ~ dt_start, data = MPsample)
  points(MPsample[, "dt_start"], Mconddt_start, pch = 20, col = "red")
}
```

```{R, animation.hook="gifski", interval = 0.3}
variance_initial_state <- c()
variance_A <- c()
variance_alpha <- c()
variance_tolerance <- c()
variance_factor <- c()
variance_dt_start <- c()
variance_model <- c()

for (i in c(2:length(points_for_evaluation))) {
  MPsample <- cbind(M = simulation_results_approx[, i], both_sample_global)
  VARM <- var(simulation_results_approx[, i])
  variance_model <- c(variance_model, VARM)
  SDM <- sd(simulation_results_approx[, i])
  ANOVA1 <- sample.vardecomp(MPsample)
  variance_initial_state <- c(variance_initial_state, ANOVA1[[1]])
  variance_A <- c(variance_A, ANOVA1[[2]])
  variance_alpha <- c(variance_alpha, ANOVA1[[3]])
  variance_tolerance <- c(variance_tolerance, ANOVA1[[4]])
  variance_factor <- c(variance_factor, ANOVA1[[5]])
  variance_dt_start <- c(variance_dt_start, ANOVA1[[6]])

  added_var <- 0
  for (j in c(1:length(ANOVA1))) {
    added_var <- added_var + ANOVA1[[j]]
  }
  pie(ANOVA1,
    main = paste(
      "Variance of M =", VARM, "at t =", i - 1,
      "\nRemaining variance is", VARM - added_var
    ),
    col = rainbow(5),
    radius = 1
  )
}
```


```{R}
# create a dataset
parameters <- (c(rep("initial_state", length(points_for_evaluation) - 1), rep("A", length(points_for_evaluation) - 1), rep("alpha", length(points_for_evaluation) - 1), rep("tolerance", length(points_for_evaluation) - 1), rep("factor", length(points_for_evaluation) - 1), rep("dt_start", length(points_for_evaluation) - 1), rep("unexplained_variance", length(points_for_evaluation) - 1)))
variance <- c(abs(variance_initial_state / variance_model), abs(variance_A / variance_model), abs(variance_alpha / variance_model), abs(variance_tolerance / variance_model), abs(variance_factor / variance_model), abs(variance_dt_start / variance_model), abs((variance_model - variance_initial_state - variance_A - variance_alpha - variance_tolerance - variance_factor - variance_dt_start) / variance_model))
time <- c(1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1), 1:(length(points_for_evaluation) - 1))
data <- data.frame(time, parameters, variance)

# Stacked
# data$parameters = relevel(data$parameters, 'unexplained_variance')
data$parameters <- factor(data$parameters, levels = c("unexplained_variance", "initial_state", "A", "alpha", "tolerance", "factor", "dt_start"))

# png("gsa_both_variance.png", width=900, height=450)
plot <- ggplot(data, aes(fill = parameters, y = variance, x = time)) +
  geom_bar(position = "stack", stat = "identity", linewidth = 0.3) +
  ggtitle("Relative contribution to variance for physical and numerical parameters") +
  xlab("Time") +
  ylab("Relative contribution to variance")
print(plot)
# dev.off()
```

## Hupsel Model
### Variable time-stepping Hupsel
```{r}
## loading input and observed data
hupsel_dat <- read.table(file = "hupsel.dat")
hupsel_time <- hupsel_dat$V1
hupsel_Qin <- hupsel_dat$V2
hupsel_Qobs <- hupsel_dat$V3

# to make data continuous for all dt
approximate_Qin <- approxfun(x = hupsel_time, y = hupsel_Qin, rule = 2:2)
approximate_Qobs <- approxfun(x = hupsel_time, y = hupsel_Qobs, rule = 2:2)

# Load custom functions for Hupsel
source("hupsel_functions.R")

## time aspects
begin_time <- 0 # begin time of the simulation
end_time <- tail(hupsel_time, 1) # end time of the simulation
dt_start <- 1 #delta t; time discretisation

# reservoir parameters
res_alpha_lw <- 0.18 # decay constant of the lower reservoir
res_alpha_up <- 0.4 # decay constant of the upper reservoir
res_lvl_up <- 0.9 # height of the outlet of the upper reservoir
res_A <- 1.6    #reservoir volume

init_state <- 0.5 # the initial state of the linear reservoir

#time-stepping parameters
tolerance <- 10^-5
factor <- 0.9
iterations <- 0

#run the model
simulation_hepsel_results <- simulate_hupsel(begin_time, end_time, dt_start, init_state, res_A, res_alpha_lw, res_alpha_up, res_lvl_up, factor, tolerance, calculate_rk4_hupsel, calculate_rk5_hupsel)

#calculate water partitioning
water_level_above_upper <- calculate_water_level_above_upper(res_lvl_up, simulation_hepsel_results)
Qout_upper <- water_level_above_upper
IQout <- which(water_level_above_upper > 0)
Qout_upper[IQout] <- res_alpha_up * (Qout_upper[IQout] - res_lvl_up)
# Qout.up = res.alpha.up*(state.above[state.above>0]-res.lvl.up)

Qout_lower <- c()
Qout_lower <- res_alpha_lw * simulation_hepsel_results$state
# Qout.lw = res.A*res.k.lw*result.state

## water balance
## dV/dt = Qin - Qout.lw - Qout.up
## dV/dt = state*res.A/dt_start
nrsteps <- length(simulation_hepsel_results$state) - 1
dVdt <- diff(simulation_hepsel_results$state) * res_A / dt_start
Qin <- approximate_Qin(simulation_hepsel_results$time)
error <- Qin[1:nrsteps] - Qout_lower[1:nrsteps] - Qout_upper[1:nrsteps] - dVdt

plot(simulation_hepsel_results$time, Qin,
  type = "l",
  ylim = c(min(Qin, Qout_lower, Qout_upper, dVdt), max(Qin, Qout_lower, Qout_upper, dVdt)),
  ylab = "L^3/T", xlab = "time"
)
legend("topleft", c(
  "Qin : black",
  "Qout.lw : blue",
  "Qout.up : green",
  "dVdt: red",
  "error : dashed"
))

lines(simulation_hepsel_results$time[1:nrsteps], dVdt, col = "red")
lines(simulation_hepsel_results$time[1:nrsteps], Qout_lower[1:nrsteps], col = "blue")
lines(simulation_hepsel_results$time[1:nrsteps], Qout_upper[1:nrsteps], col = "green")
lines(simulation_hepsel_results$time[1:nrsteps], error, lty = "dashed")

## results observed vs computed
plot(simulation_hepsel_results$time[1:nrsteps], approximate_Qobs(simulation_hepsel_results$time[1:nrsteps]),
  type = "l",
  lwd = 2, col = "grey", ylim = c(min(hupsel_Qobs, Qout_lower, Qout_upper), max(hupsel_Qobs, Qout_lower, Qout_upper)),
  ylab = "Qout.obs/Qout.calc", xlab = "time"
)
lines(simulation_hepsel_results$time[1:nrsteps], Qout_upper[1:nrsteps] + Qout_lower[1:nrsteps], col = "blue")

#calculate performance metrics
RMSE = sqrt(mean((approximate_Qobs(simulation_hepsel_results$time) - (Qout_upper + Qout_lower))^2))
mean_obs = mean(approximate_Qobs(simulation_hepsel_results$time))
obs_var = sum((approximate_Qobs(simulation_hepsel_results$time) - mean_obs)^2)
NSE = 1 - (sum((approximate_Qobs(simulation_hepsel_results$time) - (Qout_upper + Qout_lower))^2) / obs_var) #Nash-Sutcliffe efficiency
title(main = paste("Original time-stepping", "RMSE = ", round(RMSE, digits = 2), "\n NSE = ", round(NSE, digits = 2)))
```

### Fixed time-stepping Hupsel
```{r}
## loading input and observed data
hupsel_dat <- read.table(file = "hupsel.dat")
hupsel_time <- hupsel_dat$V1
hupsel_Qin <- hupsel_dat$V2
hupsel_Qobs <- hupsel_dat$V3
# to make data continuous for al dt
approximate_Qobs <- approxfun(x = hupsel_time, y = hupsel_Qin, rule = 2:2)
approximate_Qobs <- approxfun(x = hupsel_time, y = hupsel_Qobs, rule = 2:2)

# Load custom functions for Hupsel
source("hupsel_functions.R")

## time aspects
begin_time <- 0 # begin time of the simulation
end_time <- tail(hupsel_time, 1) # end time of the simulation
dt <- 4 # 1.0#.5 #delta t; time discretisation

# reservoir parameters
res_alpha_lw <- 0.18 # decay constant of the lower reservoir
res_alpha_up <- 0.4 # decay constant of the upper reservoir
res_lvl_up <- 0.9 # height of the outlet of the upper reservoir
res_A <- 1.6    #reservoir volume

init_state <- 0.5 # the initial state of the linear reservoir

#run the model
simulation_fixed_hepsel_results <- simulate_fixed_hupsel(begin_time, end_time, dt, init_state, res_A, res_alpha_lw, res_alpha_up, res_lvl_up)

#calculate water partitioning
water_level_above_upper <- calculate_water_level_above_upper(res_lvl_up, simulation_fixed_hepsel_results)
Qout_upper <- water_level_above_upper
IQout <- which(water_level_above_upper > 0)
Qout_upper[IQout] <- res_alpha_up * (Qout_upper[IQout] - res_lvl_up)
# Qout.up = res.alpha.up*(state.above[state.above>0]-res.lvl.up)

Qout_lower <- c()
Qout_lower <- res_alpha_lw * simulation_fixed_hepsel_results$state
# Qout.lw = res.A*res.k.lw*result.state

## balance
## dV/dt = Qin - Qout.lw - Qout.up
## dV/dt = state*res.A/dt
nrsteps <- length(simulation_fixed_hepsel_results$state) - 1
dVdt <- diff(simulation_fixed_hepsel_results$state) * res_A / dt
Qin <- approximate_Qobs(simulation_fixed_hepsel_results$time)
error <- Qin[1:nrsteps] - Qout_lower[1:nrsteps] - Qout_upper[1:nrsteps] - dVdt

plot(simulation_fixed_hepsel_results$time, Qin,
  type = "l",
  ylim = c(min(Qin, Qout_lower, Qout_upper, dVdt), max(Qin, Qout_lower, Qout_upper, dVdt)),
  ylab = "L^3/T", xlab = "time"
)
legend("topleft", c(
  "Qin : black",
  "Qout.lw : blue",
  "Qout.up : green",
  "dVdt: red",
  "error : dashed"
))

lines(simulation_fixed_hepsel_results$time[1:nrsteps], dVdt, col = "red")
lines(simulation_fixed_hepsel_results$time[1:nrsteps], Qout_lower[1:nrsteps], col = "blue")
lines(simulation_fixed_hepsel_results$time[1:nrsteps], Qout_upper[1:nrsteps], col = "green")
lines(simulation_fixed_hepsel_results$time[1:nrsteps], error, lty = "dashed")

## results observed vs computed
plot(simulation_fixed_hepsel_results$time[1:nrsteps], approximate_Qobs(simulation_fixed_hepsel_results$time[1:nrsteps]),
  type = "l",
  lwd = 2, col = "grey", ylim = c(min(hupsel_Qobs, Qout_lower, Qout_upper), max(hupsel_Qobs, Qout_lower, Qout_upper)),
  ylab = "Qout_obs/Qout_calc", xlab = "time"
)
lines(simulation_fixed_hepsel_results$time[1:nrsteps], Qout_upper[1:nrsteps] + Qout_lower[1:nrsteps], col = "blue")

#calculate performance metrics
RMSE = sqrt(mean((approximate_Qobs(simulation_fixed_hepsel_results$time) - (Qout_upper + Qout_lower))^2))
mean_obs = mean(approximate_Qobs(simulation_fixed_hepsel_results$time))
obs_var = sum((approximate_Qobs(simulation_fixed_hepsel_results$time) - mean_obs)^2)
NSE = 1 - (sum((approximate_Qobs(simulation_fixed_hepsel_results$time) - (Qout_upper + Qout_lower))^2) / obs_var) #Nash-Sutcliffe efficiency
title(main = paste("Fixed time-stepping", "\n RMSE = ", round(RMSE, digits = 3), " NSE = ", round(NSE, digits = 2)))
```

